#!/usr/bin/env python
"""
å¯è§†åŒ– eval_data.pkl æ–‡ä»¶ä¸ºå›¾è¡¨

ç”¨æ³•:
    # ç”Ÿæˆæ‰€æœ‰å›¾è¡¨
    python tools/visualize_pkl.py output/test/result_plots/nat2021l/eval_data.pkl
    
    # æŒ‡å®šä¿å­˜ç›®å½•
    python tools/visualize_pkl.py eval_data.pkl --output_dir ./plots
    
    # åªç”Ÿæˆç‰¹å®šå›¾è¡¨
    python tools/visualize_pkl.py eval_data.pkl --plots success prec
    
    # æ˜¾ç¤ºå›¾è¡¨ï¼ˆè€Œéåªä¿å­˜ï¼‰
    python tools/visualize_pkl.py eval_data.pkl --show
"""

import pickle
import argparse
import matplotlib.pyplot as plt
import matplotlib
import numpy as np
import torch
from pathlib import Path

# è®¾ç½®ä¸“ä¸šå­¦æœ¯è®ºæ–‡é…è‰²æ–¹æ¡ˆ
# ä½¿ç”¨æ·±è‰²ã€é¥±å’Œåº¦é€‚ä¸­çš„é¢œè‰²ï¼Œé€‚åˆè®ºæ–‡æ‰“å°å’Œå±•ç¤º
ACADEMIC_COLORS = [
    '#1f77b4',  # æ·±è“è‰² - ä¸“ä¸šã€ç¨³é‡
    '#d62728',  # æ·±çº¢è‰² - å¯¹æ¯”å¼ºçƒˆ
    '#2ca02c',  # æ·±ç»¿è‰² - æ¸…æ™°å¯è¾¨
    '#ff7f0e',  # æ©™è‰² - æ¸©æš–æ˜äº®
    '#9467bd',  # ç´«è‰² - ä¼˜é›…é«˜è´µ
    '#8c564b',  # æ£•è‰² - æ²‰ç¨³å†…æ•›
    '#e377c2',  # ç²‰è‰² - æŸ”å’Œå¯¹æ¯”
    '#7f7f7f',  # ç°è‰² - ä¸­æ€§å¹³è¡¡
    '#bcbd22',  # é»„ç»¿è‰² - æ´»åŠ›å››å°„
    '#17becf',  # é’è‰² - æ¸…æ–°æ˜å¿«
]

# è®¾ç½®matplotlibå…¨å±€æ ·å¼
plt.rcParams['font.sans-serif'] = ['DejaVu Sans']
plt.rcParams['axes.unicode_minus'] = False
plt.rcParams['figure.figsize'] = [12, 8]
plt.rcParams['axes.linewidth'] = 1.5
plt.rcParams['grid.linewidth'] = 0.8
plt.rcParams['lines.linewidth'] = 2.5
plt.rcParams['font.size'] = 11
plt.rcParams['axes.labelsize'] = 12
plt.rcParams['axes.titlesize'] = 14
plt.rcParams['xtick.labelsize'] = 11
plt.rcParams['ytick.labelsize'] = 11
plt.rcParams['legend.fontsize'] = 11
plt.rcParams['figure.titlesize'] = 16


def get_tracker_display_name(tracker):
    """è·å– tracker æ˜¾ç¤ºåç§°"""
    if tracker.get('disp_name'):
        return tracker['disp_name']
    elif tracker.get('run_id') is not None:
        return f"{tracker['name']}_{tracker['param']}_{tracker['run_id']:03d}"
    else:
        return f"{tracker['name']}_{tracker['param']}"


def plot_success_curve(data, output_dir, show=False):
    """ç»˜åˆ¶æˆåŠŸç‡æ›²çº¿ï¼ˆAUCï¼‰"""
    print("ğŸ“Š ç»˜åˆ¶æˆåŠŸç‡æ›²çº¿ (Success Plot / AUC)...")
    
    threshold_set = torch.tensor(data['threshold_set_overlap'])
    ave_success_rate = torch.tensor(data['ave_success_rate_plot_overlap'])
    valid_sequence = torch.tensor(data['valid_sequence'], dtype=torch.bool)
    trackers = data['trackers']
    
    # åªå–æœ‰æ•ˆåºåˆ—
    ave_success_rate = ave_success_rate[valid_sequence, :, :]
    auc_curve = ave_success_rate.mean(0) * 100.0  # (num_trackers, num_thresholds)
    auc = auc_curve.mean(-1)  # (num_trackers,)
    
    # ç»˜å›¾
    fig, ax = plt.subplots(figsize=(10, 7))
    
    colors = [ACADEMIC_COLORS[i % len(ACADEMIC_COLORS)] for i in range(len(trackers))]
    
    for trk_id, (tracker, color) in enumerate(zip(trackers, colors)):
        name = get_tracker_display_name(tracker)
        auc_score = auc[trk_id].item()
        
        ax.plot(threshold_set.numpy(), auc_curve[trk_id, :].numpy(),
                label=f'{name} [AUC: {auc_score:.2f}]',
                linewidth=2.5, color=color)
    
    ax.set_xlabel('Overlap threshold', fontsize=14, fontweight='bold')
    ax.set_ylabel('Success rate [%]', fontsize=14, fontweight='bold')
    ax.set_title('Success Plot (AUC)', fontsize=16, fontweight='bold')
    ax.grid(True, alpha=0.3)
    ax.legend(loc='lower left', fontsize=12)
    ax.set_xlim([0, 1])
    ax.set_ylim([0, 100])
    
    plt.tight_layout()
    
    # ä¿å­˜
    save_path = output_dir / 'success_plot.png'
    plt.savefig(save_path, dpi=150, bbox_inches='tight')
    print(f"   âœ… å·²ä¿å­˜: {save_path}")
    
    if show:
        plt.show()
    else:
        plt.close()


def plot_precision_curve(data, output_dir, show=False, normalized=False):
    """ç»˜åˆ¶ç²¾åº¦æ›²çº¿"""
    curve_type = "å½’ä¸€åŒ–ç²¾åº¦" if normalized else "ç²¾åº¦"
    print(f"ğŸ“Š ç»˜åˆ¶{curve_type}æ›²çº¿ (Precision Plot)...")
    
    if normalized:
        threshold_set = torch.tensor(data['threshold_set_center_norm'])
        ave_precision_rate = torch.tensor(data['ave_success_rate_plot_center_norm'])
        filename = 'normalized_precision_plot.png'
        title = 'Normalized Precision Plot'
        xlabel = 'Location error threshold'
    else:
        threshold_set = torch.tensor(data['threshold_set_center'])
        ave_precision_rate = torch.tensor(data['ave_success_rate_plot_center'])
        filename = 'precision_plot.png'
        title = 'Precision Plot'
        xlabel = 'Location error threshold [pixels]'
    
    valid_sequence = torch.tensor(data['valid_sequence'], dtype=torch.bool)
    trackers = data['trackers']
    
    # åªå–æœ‰æ•ˆåºåˆ—
    ave_precision_rate = ave_precision_rate[valid_sequence, :, :]
    prec_curve = ave_precision_rate.mean(0) * 100.0
    prec_score = prec_curve[:, 20]  # Precision at threshold 20
    
    # ç»˜å›¾
    fig, ax = plt.subplots(figsize=(10, 7))
    
    colors = [ACADEMIC_COLORS[i % len(ACADEMIC_COLORS)] for i in range(len(trackers))]
    
    for trk_id, (tracker, color) in enumerate(zip(trackers, colors)):
        name = get_tracker_display_name(tracker)
        score = prec_score[trk_id].item()
        
        ax.plot(threshold_set.numpy(), prec_curve[trk_id, :].numpy(),
                label=f'{name} [Prec: {score:.2f}]',
                linewidth=2.5, color=color)
    
    ax.set_xlabel(xlabel, fontsize=14, fontweight='bold')
    ax.set_ylabel('Precision [%]', fontsize=14, fontweight='bold')
    ax.set_title(title, fontsize=16, fontweight='bold')
    ax.grid(True, alpha=0.3)
    ax.legend(loc='lower right', fontsize=12)
    
    if normalized:
        ax.set_xlim([0, 0.5])
    else:
        ax.set_xlim([0, 50])
    ax.set_ylim([0, 100])
    
    plt.tight_layout()
    
    # ä¿å­˜
    save_path = output_dir / filename
    plt.savefig(save_path, dpi=150, bbox_inches='tight')
    print(f"   âœ… å·²ä¿å­˜: {save_path}")
    
    if show:
        plt.show()
    else:
        plt.close()


def plot_comparison_bar(data, output_dir, show=False):
    """ç»˜åˆ¶æ€§èƒ½å¯¹æ¯”æŸ±çŠ¶å›¾"""
    print("ğŸ“Š ç»˜åˆ¶æ€§èƒ½å¯¹æ¯”æŸ±çŠ¶å›¾...")
    
    trackers = data['trackers']
    valid_sequence = torch.tensor(data['valid_sequence'], dtype=torch.bool)
    
    # è®¡ç®—å„é¡¹æŒ‡æ ‡
    threshold_set_overlap = torch.tensor(data['threshold_set_overlap'])
    ave_success_rate_plot_overlap = torch.tensor(data['ave_success_rate_plot_overlap'])
    ave_success_rate_plot_overlap = ave_success_rate_plot_overlap[valid_sequence, :, :]
    auc_curve = ave_success_rate_plot_overlap.mean(0) * 100.0
    
    # æ‰¾åˆ°å¯¹åº”é˜ˆå€¼çš„ç´¢å¼•
    op50_idx = (threshold_set_overlap == 0.50).nonzero(as_tuple=True)[0][0].item()
    op75_idx = (threshold_set_overlap == 0.75).nonzero(as_tuple=True)[0][0].item()
    
    metrics = {}
    metrics['AUC'] = auc_curve.mean(-1).numpy().tolist()
    metrics['OP50'] = auc_curve[:, op50_idx].numpy().tolist()
    metrics['OP75'] = auc_curve[:, op75_idx].numpy().tolist()
    
    if 'ave_success_rate_plot_center' in data:
        ave_prec = torch.tensor(data['ave_success_rate_plot_center'])
        ave_prec = ave_prec[valid_sequence, :, :]
        prec_curve = ave_prec.mean(0) * 100.0
        metrics['Precision'] = prec_curve[:, 20].numpy().tolist()
    
    if 'ave_success_rate_plot_center_norm' in data:
        ave_norm_prec = torch.tensor(data['ave_success_rate_plot_center_norm'])
        ave_norm_prec = ave_norm_prec[valid_sequence, :, :]
        norm_prec_curve = ave_norm_prec.mean(0) * 100.0
        metrics['Norm Prec'] = norm_prec_curve[:, 20].numpy().tolist()
    
    # ç»˜åˆ¶æŸ±çŠ¶å›¾
    fig, ax = plt.subplots(figsize=(12, 7))
    
    tracker_names = [get_tracker_display_name(t) for t in trackers]
    x = np.arange(len(metrics))
    width = 0.8 / len(trackers)
    
    colors = [ACADEMIC_COLORS[i % len(ACADEMIC_COLORS)] for i in range(len(trackers))]
    
    # ç¡®ä¿æ‰€æœ‰metricsçš„å€¼éƒ½æ˜¯æ ‡é‡åˆ—è¡¨
    for key in metrics:
        if isinstance(metrics[key], np.ndarray):
            if metrics[key].ndim == 0:
                metrics[key] = [float(metrics[key])]
            else:
                metrics[key] = metrics[key].tolist()
    
    for trk_id, (name, color) in enumerate(zip(tracker_names, colors)):
        offset = (trk_id - len(trackers)/2 + 0.5) * width
        values = [float(metrics[metric][trk_id]) for metric in metrics.keys()]
        ax.bar(x + offset, values, width, label=name, color=color, alpha=0.85, edgecolor='white', linewidth=1.2)
    
    ax.set_xlabel('æŒ‡æ ‡', fontsize=14, fontweight='bold')
    ax.set_ylabel('åˆ†æ•° (%)', fontsize=14, fontweight='bold')
    ax.set_title('æ€§èƒ½å¯¹æ¯”', fontsize=16, fontweight='bold')
    ax.set_xticks(x)
    ax.set_xticklabels(list(metrics.keys()))
    ax.legend(fontsize=12)
    ax.grid(True, alpha=0.3, axis='y')
    ax.set_ylim([0, 100])
    
    # æ·»åŠ æ•°å€¼æ ‡ç­¾
    for trk_id in range(len(trackers)):
        offset = (trk_id - len(trackers)/2 + 0.5) * width
        for i, metric in enumerate(metrics.keys()):
            value = metrics[metric][trk_id]
            ax.text(i + offset, value + 2, f'{value:.1f}', 
                   ha='center', va='bottom', fontsize=9, fontweight='bold')
    
    plt.tight_layout()
    
    # ä¿å­˜
    save_path = output_dir / 'comparison_bar.png'
    plt.savefig(save_path, dpi=150, bbox_inches='tight')
    print(f"   âœ… å·²ä¿å­˜: {save_path}")
    
    if show:
        plt.show()
    else:
        plt.close()


def plot_per_sequence_performance(data, output_dir, show=False):
    """ç»˜åˆ¶æ¯ä¸ªåºåˆ—çš„æ€§èƒ½"""
    print("ğŸ“Š ç»˜åˆ¶æ¯åºåˆ—æ€§èƒ½...")
    
    sequences = data['sequences']
    trackers = data['trackers']
    avg_overlap_all = torch.tensor(data['avg_overlap_all']) * 100.0  # (num_seq, num_trackers)
    valid_sequence = torch.tensor(data['valid_sequence'], dtype=torch.bool)
    
    # åªæ˜¾ç¤ºæœ‰æ•ˆåºåˆ—
    valid_sequences = [seq for seq, valid in zip(sequences, valid_sequence) if valid]
    avg_overlap_valid = avg_overlap_all[valid_sequence, :]
    
    # å¦‚æœåºåˆ—å¤ªå¤šï¼Œåªæ˜¾ç¤ºå‰ 30 ä¸ª
    max_display = 30
    if len(valid_sequences) > max_display:
        print(f"   åºåˆ—æ•°è¿‡å¤š ({len(valid_sequences)})ï¼Œåªæ˜¾ç¤ºå‰ {max_display} ä¸ª")
        valid_sequences = valid_sequences[:max_display]
        avg_overlap_valid = avg_overlap_valid[:max_display, :]
    
    # ç»˜å›¾
    fig, ax = plt.subplots(figsize=(15, 8))
    
    x = np.arange(len(valid_sequences))
    width = 0.8 / len(trackers)
    colors = [ACADEMIC_COLORS[i % len(ACADEMIC_COLORS)] for i in range(len(trackers))]
    
    tracker_names = [get_tracker_display_name(t) for t in trackers]
    
    for trk_id, (name, color) in enumerate(zip(tracker_names, colors)):
        offset = (trk_id - len(trackers)/2 + 0.5) * width
        values = avg_overlap_valid[:, trk_id].numpy().tolist()
        ax.bar(x + offset, values, width, label=name, color=color, alpha=0.85, edgecolor='white', linewidth=1.2)
    
    ax.set_xlabel('åºåˆ—', fontsize=12, fontweight='bold')
    ax.set_ylabel('å¹³å‡é‡å ç‡ (%)', fontsize=12, fontweight='bold')
    ax.set_title('æ¯åºåˆ—æ€§èƒ½å¯¹æ¯”', fontsize=14, fontweight='bold')
    ax.set_xticks(x)
    ax.set_xticklabels(valid_sequences, rotation=45, ha='right', fontsize=8)
    ax.legend(fontsize=11)
    ax.grid(True, alpha=0.3, axis='y')
    ax.set_ylim([0, 100])
    
    plt.tight_layout()
    
    # ä¿å­˜
    save_path = output_dir / 'per_sequence_performance.png'
    plt.savefig(save_path, dpi=150, bbox_inches='tight')
    print(f"   âœ… å·²ä¿å­˜: {save_path}")
    
    if show:
        plt.show()
    else:
        plt.close()


def plot_all_in_one(data, output_dir, show=False):
    """ç»˜åˆ¶ç»¼åˆå›¾è¡¨ï¼ˆæ‰€æœ‰æ›²çº¿åœ¨ä¸€å¼ å›¾ï¼‰"""
    print("ğŸ“Š ç»˜åˆ¶ç»¼åˆå›¾è¡¨...")
    
    trackers = data['trackers']
    valid_sequence = torch.tensor(data['valid_sequence'], dtype=torch.bool)
    
    fig, axes = plt.subplots(2, 2, figsize=(16, 12))
    colors = [ACADEMIC_COLORS[i % len(ACADEMIC_COLORS)] for i in range(len(trackers))]
    tracker_names = [get_tracker_display_name(t) for t in trackers]
    
    # 1. Success Plot (AUC)
    ax = axes[0, 0]
    threshold_set_overlap = torch.tensor(data['threshold_set_overlap'])
    ave_success_rate = torch.tensor(data['ave_success_rate_plot_overlap'])
    ave_success_rate = ave_success_rate[valid_sequence, :, :]
    auc_curve = ave_success_rate.mean(0) * 100.0
    auc = auc_curve.mean(-1)
    
    for trk_id, (name, color) in enumerate(zip(tracker_names, colors)):
        ax.plot(threshold_set_overlap.numpy(), auc_curve[trk_id, :].numpy(),
                label=f'{name} [{auc[trk_id].item():.2f}]',
                linewidth=2.5, color=color)
    
    ax.set_xlabel('Overlap threshold', fontsize=12, fontweight='bold')
    ax.set_ylabel('Success rate [%]', fontsize=12, fontweight='bold')
    ax.set_title('Success Plot (AUC)', fontsize=14, fontweight='bold')
    ax.grid(True, alpha=0.3)
    ax.legend(loc='lower left', fontsize=10)
    ax.set_xlim([0, 1])
    ax.set_ylim([0, 100])
    
    # 2. Precision Plot
    if 'ave_success_rate_plot_center' in data:
        ax = axes[0, 1]
        threshold_set_center = torch.tensor(data['threshold_set_center'])
        ave_prec = torch.tensor(data['ave_success_rate_plot_center'])
        ave_prec = ave_prec[valid_sequence, :, :]
        prec_curve = ave_prec.mean(0) * 100.0
        prec_score = prec_curve[:, 20]
        
        for trk_id, (name, color) in enumerate(zip(tracker_names, colors)):
            ax.plot(threshold_set_center.numpy(), prec_curve[trk_id, :].numpy(),
                    label=f'{name} [{prec_score[trk_id].item():.2f}]',
                    linewidth=2.5, color=color)
        
        ax.set_xlabel('Location error threshold [pixels]', fontsize=12, fontweight='bold')
        ax.set_ylabel('Precision [%]', fontsize=12, fontweight='bold')
        ax.set_title('Precision Plot', fontsize=14, fontweight='bold')
        ax.grid(True, alpha=0.3)
        ax.legend(loc='lower right', fontsize=10)
        ax.set_xlim([0, 50])
        ax.set_ylim([0, 100])
    
    # 3. Normalized Precision Plot
    if 'ave_success_rate_plot_center_norm' in data:
        ax = axes[1, 0]
        threshold_set_norm = torch.tensor(data['threshold_set_center_norm'])
        ave_norm_prec = torch.tensor(data['ave_success_rate_plot_center_norm'])
        ave_norm_prec = ave_norm_prec[valid_sequence, :, :]
        norm_prec_curve = ave_norm_prec.mean(0) * 100.0
        norm_prec_score = norm_prec_curve[:, 20]
        
        for trk_id, (name, color) in enumerate(zip(tracker_names, colors)):
            ax.plot(threshold_set_norm.numpy(), norm_prec_curve[trk_id, :].numpy(),
                    label=f'{name} [{norm_prec_score[trk_id].item():.2f}]',
                    linewidth=2.5, color=color)
        
        ax.set_xlabel('Location error threshold', fontsize=12, fontweight='bold')
        ax.set_ylabel('Normalized Precision [%]', fontsize=12, fontweight='bold')
        ax.set_title('Normalized Precision Plot', fontsize=14, fontweight='bold')
        ax.grid(True, alpha=0.3)
        ax.legend(loc='lower right', fontsize=10)
        ax.set_xlim([0, 0.5])
        ax.set_ylim([0, 100])
    
    # 4. Performance Summary (Bar Chart)
    ax = axes[1, 1]
    
    # ç¡®ä¿æ‰€æœ‰å€¼éƒ½æ˜¯æ ‡é‡numpyæ•°ç»„
    def extract_scalar(tensor, idx):
        """ä»å¼ é‡ä¸­æå–æ ‡é‡å€¼"""
        if isinstance(tensor, torch.Tensor):
            if tensor.dim() == 0:
                return tensor.item()
            elif tensor.dim() == 1:
                return tensor[idx].item()
            else:
                return tensor[idx, 0].item() if tensor.shape[1] == 1 else tensor[idx].mean().item()
        elif isinstance(tensor, np.ndarray):
            if tensor.ndim == 0:
                return float(tensor)
            elif tensor.ndim == 1:
                return float(tensor[idx])
            else:
                return float(tensor[idx, 0]) if tensor.shape[1] == 1 else float(tensor[idx].mean())
        else:
            return float(tensor)
    
    op50_idx = (threshold_set_overlap == 0.50).nonzero(as_tuple=True)[0][0].item()
    op75_idx = (threshold_set_overlap == 0.75).nonzero(as_tuple=True)[0][0].item()
    
    metrics = {}
    metrics['AUC'] = [extract_scalar(auc, i) for i in range(len(trackers))]
    metrics['OP50'] = [extract_scalar(auc_curve[:, op50_idx], i) for i in range(len(trackers))]
    metrics['OP75'] = [extract_scalar(auc_curve[:, op75_idx], i) for i in range(len(trackers))]
    
    if 'ave_success_rate_plot_center' in data:
        metrics['Prec'] = [extract_scalar(prec_score, i) for i in range(len(trackers))]
    if 'ave_success_rate_plot_center_norm' in data:
        metrics['NPrec'] = [extract_scalar(norm_prec_score, i) for i in range(len(trackers))]
    
    x_pos = np.arange(len(metrics))
    width_bar = 0.8 / len(trackers)
    
    for trk_id, (name, color) in enumerate(zip(tracker_names, colors)):
        offset = (trk_id - len(trackers)/2 + 0.5) * width_bar
        values = [metrics[m][trk_id] for m in metrics.keys()]
        ax.bar(x_pos + offset, values, width_bar, label=name, color=color, alpha=0.85, edgecolor='white', linewidth=1.2)
        
        # æ·»åŠ æ•°å€¼æ ‡ç­¾
        for i, val in enumerate(values):
            ax.text(i + offset, val + 2, f'{val:.1f}', 
                   ha='center', va='bottom', fontsize=8, fontweight='bold')
    
    ax.set_xlabel('æŒ‡æ ‡', fontsize=12, fontweight='bold')
    ax.set_ylabel('åˆ†æ•° (%)', fontsize=12, fontweight='bold')
    ax.set_title('æ€§èƒ½æ‘˜è¦', fontsize=14, fontweight='bold')
    ax.set_xticks(x_pos)
    ax.set_xticklabels(list(metrics.keys()))
    ax.legend(fontsize=10)
    ax.grid(True, alpha=0.3, axis='y')
    ax.set_ylim([0, 100])
    
    plt.tight_layout()
    
    # ä¿å­˜
    save_path = output_dir / 'all_in_one.png'
    plt.savefig(save_path, dpi=150, bbox_inches='tight')
    print(f"   âœ… å·²ä¿å­˜: {save_path}")
    
    if show:
        plt.show()
    else:
        plt.close()


def main():
    parser = argparse.ArgumentParser(description='å¯è§†åŒ–è·Ÿè¸ªè¯„ä¼°ç»“æœ')
    parser.add_argument('pkl_file', type=str, help='eval_data.pkl æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--output_dir', '-o', type=str, default=None,
                        help='è¾“å‡ºç›®å½• (é»˜è®¤: pklæ–‡ä»¶åŒç›®å½•ä¸‹çš„ plots/)')
    parser.add_argument('--plots', '-p', nargs='+', 
                        choices=['success', 'prec', 'norm_prec', 'bar', 'per_seq', 'all', 'all_in_one'],
                        default=['all_in_one'],
                        help='è¦ç”Ÿæˆçš„å›¾è¡¨ç±»å‹')
    parser.add_argument('--show', '-s', action='store_true',
                        help='æ˜¾ç¤ºå›¾è¡¨ï¼ˆè€Œä¸åªæ˜¯ä¿å­˜ï¼‰')
    
    args = parser.parse_args()
    
    # åŠ è½½æ•°æ®
    pkl_path = Path(args.pkl_file)
    if not pkl_path.exists():
        print(f"âŒ é”™è¯¯: æ–‡ä»¶ä¸å­˜åœ¨: {pkl_path}")
        return
    
    print(f"ğŸ“‚ åŠ è½½æ–‡ä»¶: {pkl_path}")
    print("=" * 80)
    
    try:
        with open(pkl_path, 'rb') as f:
            data = pickle.load(f)
        print(f"âœ… æ–‡ä»¶åŠ è½½æˆåŠŸ\n")
    except Exception as e:
        print(f"âŒ åŠ è½½å¤±è´¥: {e}")
        return
    
    # è®¾ç½®è¾“å‡ºç›®å½•
    if args.output_dir:
        output_dir = Path(args.output_dir)
    else:
        output_dir = pkl_path.parent / 'plots'
    
    output_dir.mkdir(parents=True, exist_ok=True)
    print(f"ğŸ’¾ è¾“å‡ºç›®å½•: {output_dir}\n")
    
    # æ˜¾ç¤ºåŸºæœ¬ä¿¡æ¯
    trackers = data.get('trackers', [])
    sequences = data.get('sequences', [])
    valid_sequence = data.get('valid_sequence', [])
    
    print(f"ğŸ“Š æ•°æ®é›†ä¿¡æ¯:")
    print(f"   â€¢ åºåˆ—æ•°: {len(sequences)}")
    print(f"   â€¢ æœ‰æ•ˆåºåˆ—: {sum(valid_sequence)}")
    print(f"   â€¢ Tracker æ•°: {len(trackers)}")
    for t in trackers:
        print(f"      - {get_tracker_display_name(t)}")
    print("\n" + "=" * 80 + "\n")
    
    # ç”Ÿæˆå›¾è¡¨
    plot_types = args.plots
    if 'all' in plot_types:
        plot_types = ['success', 'prec', 'norm_prec', 'bar', 'per_seq']
    
    if 'all_in_one' in plot_types:
        plot_all_in_one(data, output_dir, args.show)
    
    if 'success' in plot_types:
        plot_success_curve(data, output_dir, args.show)
    
    if 'prec' in plot_types:
        plot_precision_curve(data, output_dir, args.show, normalized=False)
    
    if 'norm_prec' in plot_types:
        plot_precision_curve(data, output_dir, args.show, normalized=True)
    
    if 'bar' in plot_types:
        plot_comparison_bar(data, output_dir, args.show)
    
    if 'per_seq' in plot_types:
        plot_per_sequence_performance(data, output_dir, args.show)
    
    print("\n" + "=" * 80)
    print(f"ğŸ‰ å¯è§†åŒ–å®Œæˆï¼æ‰€æœ‰å›¾è¡¨å·²ä¿å­˜è‡³: {output_dir}")
    print("=" * 80)


if __name__ == '__main__':
    main()
